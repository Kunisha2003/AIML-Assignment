{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd21d39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "C:\\Users\\kunis\\AppData\\Local\\Temp\\ipykernel_29052\\1557334551.py:26: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-a))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression predictions on random data: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "SVM predictions on random data: [1 1 1 1 1 1 1 1 1 1]\n",
      "Decision Tree predictions on random data: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- NewFeature\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- PassengerId\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "data = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "data.isnull().sum()\n",
    "\n",
    "most_common_embarked = data['Embarked'].mode()[0]\n",
    "data['Embarked'].fillna(most_common_embarked, inplace=True)\n",
    "\n",
    "data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
    "data['Fare'].fillna(data['Fare'].mean(), inplace=True)\n",
    "\n",
    "X = data.drop('Survived', axis=1)\n",
    "y = data['Survived']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=35)\n",
    "\n",
    "def sigmoid(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "def logistic(x_train, x_test, learning_rate=0.05, epochs=1500):\n",
    "    c, d = x_train.shape\n",
    "    theta = np.zeros(d)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        t = np.dot(x_train, theta)\n",
    "        n = sigmoid(t)\n",
    "        gradient = np.dot(x_train.T, (n - y_train)) / c\n",
    "        theta -= learning_rate * gradient\n",
    "\n",
    "    return theta\n",
    "\n",
    "theta = logistic(x_train.values, y_train.values)\n",
    "y_pred = np.round(sigmoid(np.dot(x_test.values, theta)))\n",
    "\n",
    "svm_classifier = SVC(kernel=\"linear\")\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "svm_pred = svm_classifier.predict(x_test)\n",
    "\n",
    "def entropy(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probability = counts / len(y)\n",
    "    return -np.sum(probability * np.log2(probability))\n",
    "\n",
    "def info(x_col, y, threshold):\n",
    "    left = x_col < threshold\n",
    "    right = ~left\n",
    "    left_entropy = entropy(y[left])\n",
    "    right_entropy = entropy(y[right])\n",
    "    p_en = entropy(y)\n",
    "    return p_en - (len(y[left]) / len(y) * left_entropy + len(y[right]) / len(y) * right_entropy)\n",
    "\n",
    "best_gain = 0\n",
    "best_feature =0\n",
    "best_threshold =0\n",
    "\n",
    "for feature in range(x_train.shape[1]):\n",
    "    thresholds = np.unique(x_train.values[:, feature])\n",
    "    for threshold in thresholds:\n",
    "        gain = info(x_train.values[:, feature], y_train.values, threshold)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_feature = feature\n",
    "            best_threshold = threshold\n",
    "\n",
    "tree_pred = np.zeros_like(y_test)\n",
    "tree_pred[x_test.values[:, best_feature] < best_threshold] = 0\n",
    "tree_pred[x_test.values[:, best_feature] >= best_threshold] = 1\n",
    "\n",
    "random_data = pd.DataFrame({\n",
    "    'Pclass': np.random.randint(1, 4, size=10),\n",
    "    'Sex': np.random.randint(0, 2, size=10),\n",
    "    'Age': np.random.uniform(0, 80, size=10),\n",
    "    'SibSp': np.random.randint(0, 5, size=10),\n",
    "    'Parch': np.random.randint(0, 5, size=10),\n",
    "    'Fare': np.random.uniform(0, 300, size=10),\n",
    "    'Embarked': np.random.randint(0, 3, size=10)\n",
    "})\n",
    "\n",
    "# Update theta to match the number of features (including the new feature)\n",
    "theta = np.zeros(8)\n",
    "\n",
    "random_data['NewFeature'] = np.random.uniform(0, 1, size=10)\n",
    "\n",
    "random_pred_lr = np.round(sigmoid(np.dot(random_data.values, theta)))\n",
    "\n",
    "# SVM prediction on random data\n",
    "random_pred_svm = svm_classifier.predict(random_data)\n",
    "\n",
    "# Retraining decision tree after adding the new feature\n",
    "X_random = random_data.drop(columns=['NewFeature'])\n",
    "y_random = np.zeros(len(random_data))  # Placeholder, since we are generating random data\n",
    "\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "tree_classifier.fit(X_random, y_random)\n",
    "\n",
    "# Remove 'NewFeature' column before making predictions\n",
    "random_data.drop(columns=['NewFeature'], inplace=True)\n",
    "random_pred_tree = tree_classifier.predict(random_data)\n",
    "\n",
    "print(\"Logistic Regression predictions on random data:\", random_pred_lr)\n",
    "print(\"SVM predictions on random data:\", random_pred_svm)\n",
    "print(\"Decision Tree predictions on random data:\", random_pred_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7ec88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
